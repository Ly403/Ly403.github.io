<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> 离散型流匹配模型（1） | Yi Liu's Homepage. 😀 </title> <meta name="author" content="Yi LIU"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?b05f9a0b7405d7c8c89c7465593dea81"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?dadeb9c5d1fd12bc8d37475657446863"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?1fefb6021bf36010f25ea1cef24af84e"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?53a094b51ed1d1e025731eb00d240058" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%91%8B&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://ly403.github.io/blog/2025/%E7%A6%BB%E6%95%A3%E6%B5%81%E5%8C%B9%E9%85%8D%E6%A8%A1%E5%9E%8B-1/"> <script src="/assets/js/theme.js?f2531f05c6f8e1622518f4f5a1e385b1"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?46af317e693b09921dcb92261d123fbc" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Yi Liu's Homepage. 😀 </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">submenus </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/teaching/">teaching</a> </div> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">离散型流匹配模型（1）</h1> <p class="post-meta"> Created on January 05, 2025 </p> <p class="post-tags"> <a href="/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/tag/formatting"> <i class="fa-solid fa-hashtag fa-sm"></i> formatting</a>   <a href="/blog/tag/math"> <i class="fa-solid fa-hashtag fa-sm"></i> math</a>   ·   <a href="/blog/category/flow-matching"> <i class="fa-solid fa-tag fa-sm"></i> Flow_Matching</a>   <a href="/blog/category/discrete-flow-matching"> <i class="fa-solid fa-tag fa-sm"></i> Discrete_Flow_Matching</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>本文是接着上一次学习的CTMC模型继续学习离散型流匹配模型，主要是读Flow Matching Guide and Code<sup id="fnref:1"><a href="#fn:1" class="footnote" rel="footnote" role="doc-noteref">1</a></sup>第7章的笔记。并非完全Flow Matching Guide and Code的翻译，挑了一些重要的内容并且加入了我自己的的理解。</p> <p>要构建一个离散型流匹配模型（Discrete Flow Matching，DFM），分为三个步骤：</p> <ol> <li>类比连续型FM，定义一个概率路径$p_t$，连接原始分布的pmf和目标分布的pmf。pmf就是概率质量函数。</li> <li>构建一个CTMC模型，\({(X_{t})}_{0 \le t \le 1}\)，该CTMC的速度场\(u_{t}^{\theta}\)生成出第1步中的概率路径\(p_t\)，\(\theta\)是可学习的参数。</li> <li>训练\(u_{t}^{\theta}\)，使之最小化Bregman散度，Bregman散度就是DFM的损失函数。</li> </ol> <p>后面我就把离散型流匹配模型简称为DFM，连续型流匹配模型简称为FM。</p> <h2 id="数据和数据的成对">数据和数据的成对</h2> <p>像FM里面一样，定义源分布的pmf为$p$，目标分布的pmf为$q$。源分布的随机变量（Random Variable，RV）记为$X_0$，目标分布的随机变量记为$X_1$。$X_0,X_1 \in \mathcal{S}$，$\mathcal{S}$就是CTMC模型里面提到的状态空间。</p> <p>考虑到我们一般把$X_0$和$X_1$放在一起讨论，所以需要找个方式表示$X_0$和$X_1$的成对分布：$(X_0,X_1)\sim p(X_0)q(X_1)$，就是当成两个独立的RV，用二者的pmf的乘积表示$(X_0,X_1)$的联合分布。也可以用单独的符号$\pi_{0,1}(x_0,x_1)$表示$p(x_0)$和$q(x_1)$的联合分布。</p> <p>举个例子理解，如果对文本生成任务，源分布$p(x_0)$就是先验分布，一般取：</p> <ol> <li> <p>$\mathcal{S}$上的均匀分布</p> </li> <li> <p>加入一个mask的特殊token $\mathtt{m}$到vocabulary $\mathcal{T}$里面，即$\mathcal{T}\cup {\mathtt{m}}$。</p> </li> </ol> <p>按第2种方法，此时得到$\pi_{0,1}(x_0,x_1)=\delta(x_0,\mathtt{m})q(x_1)$，先验分布就是$\delta(x_0,\mathtt{m})$。若$X_0 \sim \delta(X_0,\mathtt{m})$，则$X_0=(\mathtt{m},\cdots,\mathtt{m})$。</p> <h2 id="离散概率路径">离散概率路径</h2> <p>FM<sup id="fnref:2"><a href="#fn:2" class="footnote" rel="footnote" role="doc-noteref">2</a></sup>在研究边缘概率路径$p_t(x)$和生成$p_t(x)$的边缘向量场时$u_t(x)$遇到困难（图像在高维空间中造成<sup id="fnref:2:1"><a href="#fn:2" class="footnote" rel="footnote" role="doc-noteref">2</a></sup>中的公式6和8的积分不可解，因此没办法得到$p_t(x)$和$u_t(x)$的解析式），所以转而求解条件向量场$u_t(x\mid z)$和条件概率路径$p_t(x\mid z)$。仿照这个办法，DFM也可以按如下方式算边缘概率路径（marginal probability path）：</p> \[p_t(x) = \sum_{z\in \mathcal{Z}}{p_{t\mid Z}(x\mid z)p_{Z}(z)}\tag{1}\] <p>其中$Z\in \mathcal{Z}$是作为条件的随机变量，$\mathcal{Z}$是任意空间。上式是离散版的全概率公式。需要指出的是，<strong>条件概率路径$p_{t\mid Z}(x\mid z)$必须满足边界约束$p_0 = p$和$p_1=q$，</strong>这样才能构建源分布和目标分布之间的关系。</p> <h2 id="边缘化技巧">边缘化技巧</h2> <p>我们在公式1中已经给出了边缘概率路径$p_t(x)$和条件概率路径$p_{t\mid Z}(x\mid z)$之间的关系，类比在FM里面做的事情，对DFM，我们也想知道条件速度场$u_t(y,x\mid z)$和边缘条件速度场$u_t(y,x)$之间的关系。</p> <p>为了研究这个问题，可以从FM中获得经验。FM中，如果条件向量场$u_t(\cdot\mid z)$能生成条件概率路径$p_{t\mid Z}(\cdot\mid z)$，那边缘向量场$u_t(x)$满足：</p> \[u_t(x) = \int u_t(x\mid z)\cfrac{p_{t\mid Z}(x\mid z)p_Z(z)}{p_t(x)}\mathrm{d} z =\int u_t(x\mid z) p_{Z\mid t}(z\mid x) \mathrm{d}z \tag{2}\] <p>公式2可以参考Flow matching for generative modeling<sup id="fnref:2:2"><a href="#fn:2" class="footnote" rel="footnote" role="doc-noteref">2</a></sup>里面的公式8，或者Flow Matching Guide and Code<sup id="fnref:1:1"><a href="#fn:1" class="footnote" rel="footnote" role="doc-noteref">1</a></sup>里面的公式4.12。</p> <p>类比公式2，是否DFM也存在如下关系：当条件速度场$u_t(\cdot,\cdot\mid z)$生成条件概率路径$p_{t\mid Z}(\cdot\mid z)$时，边缘速度场$u_t(y,x)$满足</p> \[u_t(y,x) = \sum_z u_t(y,x \mid z) \cfrac{p_{t\mid Z}(x\mid z)p_Z(z)}{p_t(x)} =\sum_z u_t(y,x\mid z) p_{Z\mid t}(z\mid x) \tag{3}\] <p>答案是肯定的。接下来详细表述和证明这个问题。</p> <hr> <p><strong>假设</strong> $p_{t\mid Z}(x\mid z)\in C^{1}([0,1))$。$u_t(y,x\mid z)\in C([0,1))$。对所有$t\in[0,1)$和$x\in \mathcal{S}$，$p_t(x)&gt; 0$。</p> <p><strong>定理</strong> （离散边缘化技巧）当上述假设满足时，如果$u_t(y,x\mid z)$生成$p_{t\mid Z}(x\mid z)$，那么对$t\in[0,1)$，边缘向量场$u_t(y,x)$（公式3）生成边缘概率路径$p_t(x)$（公式1）。</p> <p><strong>证明</strong></p> \[\begin{aligned} \cfrac{\mathrm{d}}{\mathrm{d}t}p_t(y) &amp;\overset{(1)}{=} \cfrac{\mathrm{d}}{\mathrm{d}t}\left[ \sum_z{ p_{t\mid Z}\left(y\mid z\right)p_{Z}(z) }\right]\\ &amp;\overset{(2)}{=} \sum_z{ \cfrac{\mathrm{d}}{\mathrm{d}t}\left[ p_{t\mid Z}\left(y\mid z\right)p_{Z}(z) \right] }\\ &amp;\overset{(3)}{=} \sum_z{ \cfrac{\mathrm{d}}{\mathrm{d}t}\left[ p_{t\mid Z}\left(y\mid z\right) \right]p_{Z}(z) }\\ &amp;\overset{(4)}{=} \sum_z {\sum_x \left[{ u_t(y,x \mid z) p_{t\mid Z}(x\mid z) } \right] p_Z(z)}\\ &amp;\overset{(5)}{=} \sum_x {\sum_z \left[{ u_t(y,x \mid z) \cfrac{p_{t\mid Z}(x\mid z)p_Z(z)}{p_t(x)} } \right] p_t(x)}\\ &amp;\overset{(6)}{=} \sum_x {\overbrace{\sum_z \left[{ u_t(y,x \mid z) p_{Z\mid t}(z\mid x) } \right]}^{u_t(y,x)} p_t(x)} \end{aligned} \tag{4}\] <p>第（4）步是因为根据条件“$u_t(y,x\mid z)$生成$p_{t\mid Z}(x\mid z)$”，我们在CTMC模型中讲到的离散质量守恒Discrete Mass Conservation（Discrete Mass Conservation的假设已经满足了，就是上文给出的假设），可知：</p> <ul> <li>$u_t(y,x\mid z)$生成$p_{t\mid Z}(x\mid z)$</li> <li> <font color="red">$u_t(y,x\mid z)$和$p_{t\mid Z}$满足Kolmogorov方程</font> <p>，且<font color="blue"> $u_t(y,x\mid z)$满足速率条件（rate conditions）</font>。</p> </li> </ul> <p>二者等价，故直接带入Kolmogorov方程可得第（4）步，只是加了个条件$z$而已。</p> <p>第（5）是将$p_Z(z)$拿到内层求和，并在内层求和的分母上添加一个$p_t(x)$，此时还需要再乘$p_t(x)$，可以用分配律把它拿出内层求和。</p> <p>第（6）步是贝叶斯公式。</p> <p>最终得出的等式比对一下Kolmogorov方程，可见$u_t(y,x)=\sum_z u_t(y,x \mid z) p_{Z\mid t}(z\mid x)$和$p_t$满足Kolmogorov方程。</p> <p>然后，$u_t(y,x)$满足速率条件，因为$u_t(y,x \mid z)$满足速率条件，即上文蓝色字的部分。</p> <blockquote> <p>关于为什么$u_t(y,x \mid z)$满足速率条件，$u_t(y,x)$就满足速率条件的证明：</p> <p>如果$u_t(y,x \mid z)$满足速率条件，那么 $\forall y\neq x , u_t(y,x\mid z) \ge 0$且$\sum_y u_t(y,x\mid z)=0$</p> <p>根据$u_t(y,x)=\sum_z u_t(y,x \mid z) p_{Z\mid t}(z\mid x)$，因为$p_{Z\mid t}(z\mid x)$显然不小于0，故$u_t(y,x) \ge 0$。</p> \[\begin{aligned} \sum_y u_t(y,x) &amp;=\sum_y\sum_z u_t(y,x \mid z) p_{Z\mid t}(z\mid x) \\ &amp;=\sum_z\sum_y u_t(y,x \mid z) p_{Z\mid t}(z\mid x) \\ &amp;= \sum_z 0p_{Z\mid t}(z\mid x) \\ &amp;= 0 \end{aligned} \tag{5}\] <p>所以$u_t(y,x)$也满足速率条件。</p> </blockquote> <p>在再次应用Discrete Mass Conservation之前，还得确定一下假设是否满足，因为$u_t(y,x\mid z)\in C([0,1)$且$p_{t\mid Z}(x\mid z)\in C^{1}([0,1))$，故$u_t(y,x)\in C([0,1))$，$p_t(x)\in C^1([0,1))$。</p> <blockquote> <p>关于为什么\(u_t(y,x\mid z)\in C([0,1)\)且\(p_{t\mid Z}(x\mid z)\in C^{1}([0,1))\)，就有\(u_t(y,x)\in C([0,1))\)。我自己的理解如下：</p> <p>因为\(p_t(x) = \sum_{z}{p_{t\mid Z}(x\mid z)p_{Z}(z)}\)，\(p_{t\mid Z}(x\mid z)\)在\(t\in[0,1)\)上连续，\(p_Z(z)\)和\(t\)无关，所以\(p_t(x)\)在\(t\in[0,1)\)连续。\(p_{t\mid Z}(x\mid z)\)的一阶导在\(t\in[0,1)\)上连续，\(p_Z(z)\)和\(t\)无关，\(\dot p_t(x) = \sum_{z}{\dot p_{t\mid Z}(x\mid z)p_{Z}(z)}\)，故\(\dot p_t(x)\)也在\(t\in[0,1)\)上连续。</p> <p>因为$u_t(y,x)=\sum_z u_t(y,x \mid z) p_{Z\mid t}(z\mid x)= \sum_z u_t(y,x \mid z) \cfrac{p_{t\mid Z}(x\mid z)p_Z(z)}{p_t(x)}$，在$t\in[0,1)$时，$p_{t\mid Z}(x\mid z)$和$u_t(y,x\mid z)$都连续，$p_Z(z)$和$t$无关，根据假设$p_t(x)&gt;0$，同时$p_t(x)$在$t\in[0,1)$连续，所以$u_t(y,x)$在$t\in[0,1)$连续。从这里能看到假设为什么一定要$p_t(x)&gt;0$。</p> <p>从上面这些解释就知道$u_t(y,x)\in C([0,1))$，$p_t(x) \in C^1([0,1)$。</p> </blockquote> <p>所以假设也满足，可以应用Discrete Mass Conservation，得到<strong>$u_t(y,x)$生成$p_{t}(x)$</strong>。证明完毕。</p> <p><strong>补充</strong> 关于$t\in[0,1)$时，$p_t&gt;0$的假设是可以满足的。因为我们可以使用$(1-(1-t)\epsilon) \cdot p_{Z\mid t} + (1 - t)\epsilon \cdot p_{\text{uni}}$，其中$p_{\text{uni}}$是均匀分布，$\epsilon$是大于0的很小的值。我的理解就是通过稍微加入一点服从均匀分布的噪声，让$[0,1)$上，$p_t$都有概率。</p> <hr> <h2 id="dfm损失">DFM损失</h2> <p>像FM里面一样，我们可以用一个神经网络来学习速度场$u_{t}^{\theta}(y,x)$，其中$\theta$是可学习的参数。类比FM，可以构建DFM的损失：</p> \[L_{DFM}(\theta) = \mathbb{E}_{t,X_t\sim p_t}D_{X_t}\big(u_t(\cdot,X_t),u_t^{\theta}(\cdot,X_t)\big) \tag{6}\] <p>这里，$t\sim U[0,1]$，$u_t(\cdot,x)\in R^{\mathcal{S}}$满足速率条件。也就是说，$u_t(\cdot,x)\in \Omega_x$，且：</p> \[\Omega_x = \left\{ v \in R^{\mathcal{S}} \mid v(y) &gt; 0 \text{ }\forall y \neq x,\text{ and } v(x) = - \sum_{y\neq x} v(y) \right\} \in R^{\mathcal{S}} \tag{7}\] <p>$\Omega_x$是凸集合。$D_{X_t}(u,v)$是Bregman散度，其使用凸函数$\Phi_x : \Omega_x \to \mathbb{R}$定义。</p> <hr> <p>Bregman的具体计算方式如下图和下式所示：</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post/DFM1-480.webp 480w,/assets/img/post/DFM1-800.webp 800w,/assets/img/post/DFM1-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/post/DFM1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Bregman的具体计算方式图示 </div> \[\displaystyle D( u,v) \ :=\ \Phi ( u) \ -\ [ \Phi ( v) \ +\ \langle u-v,\nabla \Phi ( v) \rangle ] \tag{8}\] <p>Bregman散度有一些关键的性质，在FM和DFM里面最关键的是它对第二个参数的梯度有仿射不变性（affine invariant）<sup id="fnref:3"><a href="#fn:3" class="footnote" rel="footnote" role="doc-noteref">3</a></sup>：</p> \[\nabla_v D(au_1 + b_u2, v) = a\nabla_v D(u_1,v) +b\nabla_vD(u_2,v), \text{ for any } a+b=1 \tag{9}\] <p>因为仿射不变性，可以得到$\nabla_vD(\mathbb{E}[Y] ,v) =\mathbb{E}[\nabla_v D(Y,v)]$。</p> <p>关于Bregman散度的详细信息，在知乎上已经有很好的回答了，可以参考：https://www.zhihu.com/question/22426561。</p> <hr> <p>就像在FM里面一样，我们更关注条件DFM（Conditional Discrete Flow Matching，CDFM）的损失函数形式，因为我们想仿照FM里面一样用神经网络预测条件速度场，如Flow matching for generative modeling<sup id="fnref:2:3"><a href="#fn:2" class="footnote" rel="footnote" role="doc-noteref">2</a></sup>里面的公式9所示。那么CDFM的损失就是：</p> \[L_{CDFM}(\theta) = \mathbb{E}_{t,Z,X_t\sim p_{t\mid Z}}D_{X_t}\big(u_t(\cdot,X_t \mid Z),u_t^{\theta}(\cdot,X_t)\big) \tag{10}\] <p>$u_t(\cdot,X_t \mid Z)$是目标条件速度场，$u_t^{\theta}(\cdot,X_t)$是模型学习的条件速度场。</p> <p>像FM里面一样，我们也能说明公式6和公式10的梯度一样：</p> <p><strong>定理</strong> DFM和CDFM损失的梯度相同：</p> \[\nabla_\theta L_{DFM}(\theta) =\nabla_\theta L_{CDFM}(\theta) \tag{11}\] <p>使得CDFM损失最小的$u^{\theta}_t(y, X_t)$是：</p> \[u^{\theta}_t(y,X_t) = \mathbb{E} \left[ u_t(y,X_t \mid Z) \mid X_t =x \right] \tag{12}\] <hr> <p>我参照<sup id="fnref:1:2"><a href="#fn:1" class="footnote" rel="footnote" role="doc-noteref">1</a></sup>以及一些自己的理解给了<strong>证明</strong>。</p> <p>先看公式11的证明：</p> \[\begin{aligned} \nabla_\theta L_{DFM}(\theta) &amp;= \nabla_\theta \mathbb{E}_{t,X_t\sim p_t}\left[D_{X_t}\big(u_t(y,X_t),u_t^{\theta}(y,X_t)\big)\right] \\ &amp;= \mathbb{E}_{t,X_t\sim p_t} \left[\nabla_\theta D_{X_t}\big(u_t(y,X_t),u_t^{\theta}(y,X_t)\big) \right]\\ &amp;= \mathbb{E}_{t,X_t\sim p_t} \left[\nabla_{u^{\theta}_t(y,X_t)} D_{X_t}\big(u_t(y,X_t),u_t^{\theta}(y,X_t)\big)\nabla_{\theta}u^{\theta}_t(y,X_t) \right]\\ &amp;=\mathbb{E}_{t,X_t\sim p_t} \left[\nabla_{u^{\theta}_t(y,X_t)} D_{X_t}\big( \sum_Z u_t(y,X_t \mid Z) p_{Z\mid t}(Z\mid X_t) ,u_t^{\theta}(y,X_t)\big) \nabla_{\theta}u^{\theta}_t(y,X_t) \right] \\ &amp;=\mathbb{E}_{t,X_t\sim p_t} \left[\nabla_{u^{\theta}_t(y,X_t)} D_{X_t}\left( \mathbb{E}_{Z\sim p_{Z\mid t}(Z\mid X_t)} \left[u_t(y,X_t \mid Z)\right] ,u_t^{\theta}(y,X_t) \right) \nabla_{\theta}u^{\theta}_t(y,X_t) \right] \\ &amp;=\mathbb{E}_{t,X_t\sim p_t} \left[\nabla_{u^{\theta}_t(y,X_t)} \mathbb{E}_{Z\sim p_{Z\mid t}(Z\mid X_t)} \left[ D_{X_t}\left( u_t(y,X_t \mid Z) ,u_t^{\theta}(y,X_t) \right) \nabla_{\theta}u^{\theta}_t(y,X_t)\right] \right] \\ &amp;=\mathbb{E}_{t,X_t\sim p_t} \left[ \mathbb{E}_{Z\sim p_{Z\mid t}(Z\mid X_t)} \left[ \nabla_{u^{\theta}_t(y,X_t)} D_{X_t}\left( u_t(y,X_t \mid Z) ,u_t^{\theta}(y,X_t) \right) \nabla_{\theta}u^{\theta}_t(y,X_t)\right] \right] \\ &amp;=\mathbb{E}_{t,X_t\sim p_t} \left[ \mathbb{E}_{Z\sim p_{Z\mid t}(Z\mid X_t)} \left[ \nabla_{\theta} D_{X_t}\left( u_t(y,X_t \mid Z) ,u_t^{\theta}(y,X_t) \right) \right] \right] \\ &amp;=\nabla_{\theta} \mathbb{E}_{t,X_t\sim p_t} \left[ \mathbb{E}_{Z\sim p_{Z\mid t}(Z\mid X_t)} \left[ D_{X_t}\left( u_t(y,X_t \mid Z) ,u_t^{\theta}(y,X_t) \right) \right] \right] \\ &amp;=\nabla_{\theta} \mathbb{E}_{t,X_t\sim p_{t\mid Z}(X_t \mid Z),Z\sim q(Z)} \left[ D_{X_t}\left( u_t(y,X_t \mid Z) ,u_t^{\theta}(y,X_t) \right) \right] \\ &amp;= \nabla_{\theta} L_{CDFM}(\theta) \end{aligned} \tag{13}\] <p>再看公式12的证明：</p> <p>代入公式12到$L_{CDFM}(\theta)$中，得到</p> \[L_{CDFM}(\theta) = \mathbb{E}_{t,Z,X_t\sim p_{t\mid Z}}D_{X_t}\Big(u_t(y,X_t \mid Z), \mathbb{E} \left[ u_t(y,X_t \mid Z) \mid X_t =x \right]\Big) \tag{14}\] <p>按照Bregman散度的定义，可知$L_{CDFM}(\theta) =0$，是一个全局最小值。所以使得$L_{CDFM}(\theta)$最小的$u^{\theta}_t$满足公式12。</p> <p>在Flow Matching Guide and Code<sup id="fnref:1:3"><a href="#fn:1" class="footnote" rel="footnote" role="doc-noteref">1</a></sup>21页最上面（公式4.25和4.26）还有一个更一般化的证明。</p> <hr> <p>这一节先到这里吧。</p> <hr> <div class="footnotes" role="doc-endnotes"> <ol> <li id="fn:1"> <p>Lipman Y, Havasi M, Holderrieth P, et al. Flow Matching Guide and Code[J]. arXiv preprint arXiv:2412.06264, 2024. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">↩</a> <a href="#fnref:1:1" class="reversefootnote" role="doc-backlink">↩<sup>2</sup></a> <a href="#fnref:1:2" class="reversefootnote" role="doc-backlink">↩<sup>3</sup></a> <a href="#fnref:1:3" class="reversefootnote" role="doc-backlink">↩<sup>4</sup></a></p> </li> <li id="fn:2"> <p>Lipman Y, Chen R T Q, Ben-Hamu H, et al. Flow matching for generative modeling[J]. arXiv preprint arXiv:2210.02747, 2022. <a href="#fnref:2" class="reversefootnote" role="doc-backlink">↩</a> <a href="#fnref:2:1" class="reversefootnote" role="doc-backlink">↩<sup>2</sup></a> <a href="#fnref:2:2" class="reversefootnote" role="doc-backlink">↩<sup>3</sup></a> <a href="#fnref:2:3" class="reversefootnote" role="doc-backlink">↩<sup>4</sup></a></p> </li> <li id="fn:3"> <p>Holderrieth P, Havasi M, Yim J, et al. Generator Matching: Generative modeling with arbitrary Markov processes[J]. arXiv preprint arXiv:2410.20587, 2024. <a href="#fnref:3" class="reversefootnote" role="doc-backlink">↩</a></p> </li> </ol> </div> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/%E7%A6%BB%E6%95%A3%E6%B5%81%E5%8C%B9%E9%85%8D%E6%A8%A1%E5%9E%8B-3/">离散型流匹配模型（3）</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/%E7%A6%BB%E6%95%A3%E6%B5%81%E5%8C%B9%E9%85%8D%E6%A8%A1%E5%9E%8B-2/">离散型流匹配模型（2）</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/%E8%BF%9E%E7%BB%AD%E6%97%B6%E9%97%B4%E7%9A%84%E9%A9%AC%E5%8F%AF%E5%A4%AB%E9%93%BE/">连续时间的马可夫链</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Yi LIU. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?c999e8c5281874b7534e3352f835d4c3" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?b977fe0c21b2118ed853308b1b923969"></script> <script src="/assets/js/no_defer.js?699fa7cbe3b29f831db7d5250ba3203a"></script> <script defer src="/assets/js/common.js?d3a25b46bbd2e0a751a27b173abc6e5f"></script> <script defer src="/assets/js/copy_code.js?fff63901a03063094790ffbfd4bc0cb4" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?25eff8ff4144a010e4ad7b31403102cf"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?04761245f225e3ad9e5e3f875d4e1074"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?b78cb42895d74e4fd6de6f633edcf181" type="text/javascript"></script> <script src="/assets/js/tabs.min.js?b3298908ffcca362ac4f3e3a7a7ebe94"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?230637657ac0b42e92d76e2b4c1b4764"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?ade73d6d60912d119f9c9347bc176630"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?f74bfa9a88ab862fb9df1c46146b7b7d"></script> </body> </html>